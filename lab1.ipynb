{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problème de prédiction du type de cancer de la peau : distinction entre tumeurs bénignes et malignes à l’aide de modèles d’apprentissage automatique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importer les bibliothèque essentielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: xgboost in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from xgboost) (2.2.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from xgboost) (2.24.3)\n",
      "Requirement already satisfied: scipy in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from xgboost) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from scikit-learn) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: opencv-python in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from opencv-python) (2.2.2)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.1.21-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: setuptools in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.69.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:07\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.1.21-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.69.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (405 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, idna, grpcio, google-pasta, gast, charset-normalizer, certifi, astunparse, absl-py, werkzeug, requests, ml-dtypes, markdown-it-py, h5py, tensorboard, rich, keras, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.2\n",
      "    Uninstalling numpy-2.2.2:\n",
      "      Successfully uninstalled numpy-2.2.2\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 certifi-2024.12.14 charset-normalizer-3.4.1 flatbuffers-25.1.21 gast-0.6.0 google-pasta-0.2.0 grpcio-1.69.0 h5py-3.12.1 idna-3.10 keras-3.8.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.14.0 protobuf-5.29.3 requests-2.32.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 urllib3-2.3.0 werkzeug-3.1.3 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas\n",
    "! pip install xgboost\n",
    "! pip install scikit-learn\n",
    "! pip install opencv-python\n",
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (3.8.0)\n",
      "Requirement already satisfied: absl-py in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from keras) (2.0.2)\n",
      "Requirement already satisfied: rich in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from keras) (0.14.0)\n",
      "Requirement already satisfied: ml-dtypes in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from keras) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/laris/.local/share/virtualenvs/CV50-wqJSEKW2/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from  glob import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as  np\n",
    "import pandas as pd\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import machine learning algorithms\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 13:24:59.477087: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-23 13:24:59.477657: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-23 13:24:59.479964: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-23 13:24:59.485377: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737635099.495172   16503 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737635099.498137   16503 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-23 13:24:59.508312: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition d'une classe pour charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset:\n",
    "    def __init__(self, proportion: float, root: Path, train: bool, size : tuple):\n",
    "        \"\"\"\n",
    "        Initialisation de l'objet CustomDataset avec la proportion des données à utiliser\n",
    "        et le répertoire racine contenant les images.\n",
    "\n",
    "        :param proportion: Proportion des données à charger (0 à 1).\n",
    "        :param root: Répertoire racine où se trouvent les images.\n",
    "        \"\"\"\n",
    "        self.proportion = proportion\n",
    "        self.root = root\n",
    "        self.data = {\"Features\": [], \"Target\": []}\n",
    "        self.target = [\"benign\", \"malignant\"]\n",
    "       \n",
    "        self.dataType = \"train\" if train else \"test\" \n",
    "\n",
    "        self.size =  size\n",
    "\n",
    "    def dataloader(self):\n",
    "        \"\"\"\n",
    "        Charge et traite les images depuis les répertoires 'benign' et 'malignant', \n",
    "        en appliquant une proportion des données spécifiée.\n",
    "\n",
    "        :return: Tuple contenant les caractéristiques (Features) et les cibles (Target) des données.\n",
    "        \"\"\"\n",
    "        # Chargement des images et valeurs cibles benign et malignant\n",
    "        for item in self.target:\n",
    "            \n",
    "            files = glob(os.path.join(self.root, f\"{self.dataType}/{item}/*.jpg\"))\n",
    "            num_files = int(len(files) * self.proportion)\n",
    "\n",
    "            self.data[\"Features\"].extend([cv2.resize(cv2.imread(imagePath), self.size).flatten().astype(np.float32) for imagePath in files[:num_files]])\n",
    "            self.data[\"Target\"].extend([item for _ in range(num_files)])\n",
    "   \n",
    "        return self.data[\"Features\"], self.data[\"Target\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charger les données disponibles dans un dossier dont vous connaissez le chemin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Définir le chemin vers le dossier contenant les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Définir la proportion des données à charger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = CustomDataset(proportion=proportion, root = root, train=True, size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features , target = datasets.dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(data={\"features\": features, \"target\": target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[162.0, 158.0, 223.0, 161.0, 160.0, 222.0, 168...</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[161.0, 154.0, 229.0, 166.0, 159.0, 232.0, 169...</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[164.0, 149.0, 241.0, 160.0, 147.0, 239.0, 164...</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[60.0, 79.0, 112.0, 68.0, 83.0, 115.0, 71.0, 8...</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[112.0, 126.0, 154.0, 113.0, 124.0, 154.0, 111...</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>[105.0, 95.0, 125.0, 100.0, 93.0, 120.0, 102.0...</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>[0.0, 0.0, 10.0, 0.0, 0.0, 24.0, 43.0, 55.0, 1...</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>[81.0, 95.0, 153.0, 111.0, 127.0, 186.0, 128.0...</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>[154.0, 146.0, 183.0, 145.0, 143.0, 185.0, 142...</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>[99.0, 116.0, 149.0, 96.0, 115.0, 148.0, 97.0,...</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>791 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              features     target\n",
       "0    [162.0, 158.0, 223.0, 161.0, 160.0, 222.0, 168...     benign\n",
       "1    [161.0, 154.0, 229.0, 166.0, 159.0, 232.0, 169...     benign\n",
       "2    [164.0, 149.0, 241.0, 160.0, 147.0, 239.0, 164...     benign\n",
       "3    [60.0, 79.0, 112.0, 68.0, 83.0, 115.0, 71.0, 8...     benign\n",
       "4    [112.0, 126.0, 154.0, 113.0, 124.0, 154.0, 111...     benign\n",
       "..                                                 ...        ...\n",
       "786  [105.0, 95.0, 125.0, 100.0, 93.0, 120.0, 102.0...  malignant\n",
       "787  [0.0, 0.0, 10.0, 0.0, 0.0, 24.0, 43.0, 55.0, 1...  malignant\n",
       "788  [81.0, 95.0, 153.0, 111.0, 127.0, 186.0, 128.0...  malignant\n",
       "789  [154.0, 146.0, 183.0, 145.0, 143.0, 185.0, 142...  malignant\n",
       "790  [99.0, 116.0, 149.0, 96.0, 115.0, 148.0, 97.0,...  malignant\n",
       "\n",
       "[791 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.DataFrame(train['features'].tolist(), columns=[f'feature_{i+1}' for i in range(len(train['features'][0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_150519</th>\n",
       "      <th>feature_150520</th>\n",
       "      <th>feature_150521</th>\n",
       "      <th>feature_150522</th>\n",
       "      <th>feature_150523</th>\n",
       "      <th>feature_150524</th>\n",
       "      <th>feature_150525</th>\n",
       "      <th>feature_150526</th>\n",
       "      <th>feature_150527</th>\n",
       "      <th>feature_150528</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>...</td>\n",
       "      <td>218.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>...</td>\n",
       "      <td>221.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>155.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>...</td>\n",
       "      <td>153.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>105.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>155.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>183.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>81.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>...</td>\n",
       "      <td>202.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>154.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>...</td>\n",
       "      <td>181.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>99.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>791 rows × 150528 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0        162.0      158.0      223.0      161.0      160.0      222.0   \n",
       "1        161.0      154.0      229.0      166.0      159.0      232.0   \n",
       "2        164.0      149.0      241.0      160.0      147.0      239.0   \n",
       "3         60.0       79.0      112.0       68.0       83.0      115.0   \n",
       "4        112.0      126.0      154.0      113.0      124.0      154.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "786      105.0       95.0      125.0      100.0       93.0      120.0   \n",
       "787        0.0        0.0       10.0        0.0        0.0       24.0   \n",
       "788       81.0       95.0      153.0      111.0      127.0      186.0   \n",
       "789      154.0      146.0      183.0      145.0      143.0      185.0   \n",
       "790       99.0      116.0      149.0       96.0      115.0      148.0   \n",
       "\n",
       "     feature_7  feature_8  feature_9  feature_10  ...  feature_150519  \\\n",
       "0        168.0      161.0      222.0       171.0  ...           200.0   \n",
       "1        169.0      162.0      237.0       167.0  ...           218.0   \n",
       "2        164.0      146.0      239.0       164.0  ...           221.0   \n",
       "3         71.0       86.0      118.0        69.0  ...           155.0   \n",
       "4        111.0      125.0      154.0       107.0  ...           153.0   \n",
       "..         ...        ...        ...         ...  ...             ...   \n",
       "786      102.0       93.0      120.0       110.0  ...           155.0   \n",
       "787       43.0       55.0      109.0        67.0  ...           183.0   \n",
       "788      128.0      144.0      211.0       123.0  ...           202.0   \n",
       "789      142.0      141.0      181.0       158.0  ...           181.0   \n",
       "790       97.0      117.0      152.0        96.0  ...           121.0   \n",
       "\n",
       "     feature_150520  feature_150521  feature_150522  feature_150523  \\\n",
       "0             132.0           140.0           199.0           130.0   \n",
       "1             158.0           153.0           222.0           158.0   \n",
       "2             145.0           137.0           220.0           143.0   \n",
       "3             125.0           132.0           157.0           120.0   \n",
       "4             111.0           122.0           150.0           104.0   \n",
       "..              ...             ...             ...             ...   \n",
       "786           146.0           134.0           152.0           144.0   \n",
       "787            97.0           118.0           186.0           100.0   \n",
       "788           111.0           130.0           197.0           116.0   \n",
       "789           166.0           151.0           182.0           181.0   \n",
       "790            91.0           100.0           120.0            90.0   \n",
       "\n",
       "     feature_150524  feature_150525  feature_150526  feature_150527  \\\n",
       "0             141.0           198.0           132.0           144.0   \n",
       "1             153.0           222.0           157.0           152.0   \n",
       "2             135.0           218.0           138.0           132.0   \n",
       "3             127.0           154.0           118.0           124.0   \n",
       "4             118.0           146.0           100.0           114.0   \n",
       "..              ...             ...             ...             ...   \n",
       "786           132.0           152.0           145.0           133.0   \n",
       "787           119.0           186.0            90.0           109.0   \n",
       "788           134.0           199.0           104.0           122.0   \n",
       "789           152.0           185.0           162.0           147.0   \n",
       "790            98.0           121.0            88.0            96.0   \n",
       "\n",
       "     feature_150528  \n",
       "0             202.0  \n",
       "1             214.0  \n",
       "2             214.0  \n",
       "3             153.0  \n",
       "4             143.0  \n",
       "..              ...  \n",
       "786           153.0  \n",
       "787           176.0  \n",
       "788           187.0  \n",
       "789           179.0  \n",
       "790           119.0  \n",
       "\n",
       "[791 rows x 150528 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder la variable cible pour pouvoir faire l'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column. \n",
    "train[\"target\"]= label_encoder.fit_transform(train[\"target\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = Train.values\n",
    "Y_Train = train[\"target\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### À l'aide de sklearn, écrivez une fonction pour diviser les données en ensemble d'apprentissage et de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X_Train, Y_Train, test_size=0.25, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### À l'aide de différents algorithmes de scikit-learn, entraînez le modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faire l'inférence du modèle construit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problème de prédiction du type de cancer de la peau : distinction entre tumeurs bénignes et malignes à l’aide de modèles d’apprentissage profond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En utilisant l'ensemble d'entraînement et l'ensemble de validation, définissez un modèle d'apprentissage profond.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() # Create sequential model\n",
    "\n",
    "# Add network layers\n",
    "model.add(Dense(.., ..))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sommaire des différentes couches de votre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définir la fonction coût"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définir l'algorithme d'optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définir la métrique d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiler votre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définir le nombre d'époques et le nombre d'exemples à mettre dans l'algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=1\n",
    "epochs=...\n",
    "batch_size = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraîner le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model \n",
    "history = model.fit(train, train, \n",
    "                              epochs=epochs, \n",
    "                              batch_size=batch_size, \n",
    "                              verbose=verbose,\n",
    "                              validation_split=0.2,\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction coût pour l'ensemble d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "print(history.history['val_accuracy'][-1])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Continuer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV50-wqJSEKW2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
